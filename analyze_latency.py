import json
import os

# é…ç½®æ•°æ®æ–‡ä»¶è·¯å¾„
DATA_FILE = 'stats.jsonl'

# ä¸­è‹±æ–‡å¯¹ç…§å­—å…¸
LABELS = {
    'total': 'æ€»è€—æ—¶ (Total Latency)',
    'conversion': 'æ ¼å¼è½¬æ¢ (Audio Conversion)',
    'vad': 'é™éŸ³æ£€æµ‹ (VAD)',
    'trim': 'é™éŸ³è£å‰ª (Silence Trimming)',
    'asr': 'è¯­éŸ³è¯†åˆ« (ASR)',
    'llm': 'å¤§è„‘æ€è€ƒ (LLM Response)'
}


def load_data():
    """è¯»å– JSONL æ–‡ä»¶ä¸­çš„æ‰€æœ‰æ•°æ®"""
    records = []
    if not os.path.exists(DATA_FILE):
        print(f"âš ï¸ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶: {DATA_FILE}")
        return records

    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try:
                    records.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
    return records


def calculate_clean_average(values):
    """
    ä½¿ç”¨ IQR (å››åˆ†ä½è·) ç®—æ³•æ’é™¤å¼‚å¸¸å€¼å¹¶è®¡ç®—å¹³å‡å€¼ã€‚
    èƒ½å¤Ÿæœ‰æ•ˆè¿‡æ»¤æ‰å¶å°”æé«˜æˆ–æä½çš„å»¶è¿Ÿæ•°æ®ã€‚
    """
    if not values:
        return 0, 0, 0  # average, total_count, outlier_count

    n = len(values)
    # æ ·æœ¬å¤ªå°‘ä¸é€‚åˆæ’é™¤å¼‚å¸¸å€¼ï¼Œç›´æ¥ç®—å¹³å‡
    if n < 4:
        return sum(values) / n, n, 0

    sorted_vals = sorted(values)
    q1 = sorted_vals[n // 4]
    q3 = sorted_vals[3 * n // 4]
    iqr = q3 - q1

    # å®šä¹‰æ­£å¸¸èŒƒå›´ï¼ˆä¸Šä¸‹è¾¹ç•Œï¼‰
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr

    # è¿‡æ»¤æ•°æ®
    clean_values = [x for x in values if lower_bound <= x <= upper_bound]
    outliers_count = n - len(clean_values)

    if not clean_values:
        return 0, n, outliers_count

    return sum(clean_values) / len(clean_values), n, outliers_count


def analyze_subset(records, count):
    """åˆ†ææœ€è¿‘ N æ¬¡çš„è®°å½•"""
    # æˆªå–æœ€è¿‘çš„ N æ¡è®°å½•
    subset = records[-count:]
    actual_count = len(subset)

    if actual_count == 0:
        return

    print(f"\n{'=' * 75}")
    print(f" ğŸ“ˆ æŠ¥å‘Š: æœ€è¿‘ {actual_count} æ¬¡å¯¹è¯åˆ†æ (Report: Last {actual_count} Conversations)")
    print(f"{'=' * 75}")
    print(f"{'æŒ‡æ ‡ (Metric)':<35} | {'å¹³å‡å»¶è¿Ÿ (Average)':<20} | {'å·²æ’é™¤å¼‚å¸¸å€¼ (Outliers Excluded)'}")
    print("-" * 75)

    keys_to_analyze = ['total', 'conversion', 'vad', 'trim', 'asr', 'llm']

    for key in keys_to_analyze:
        # æå–è¯¥æŒ‡æ ‡çš„æ‰€æœ‰æ•°å€¼
        values = [r.get(key, 0) for r in subset if key in r]

        # è®¡ç®—å‰”é™¤å¼‚å¸¸å€¼åçš„å¹³å‡å€¼
        avg_val, total_items, outliers = calculate_clean_average(values)

        # è¾“å‡ºåŒè¯­è¡¨æ ¼
        label = LABELS.get(key, key)
        print(f"{label:<33} | {avg_val:>10.2f} ms         | {outliers} æ¬¡ (Count)")

    print("=" * 75)


def main():
    records = load_data()
    total_records = len(records)

    if total_records == 0:
        return

    print(f"\nğŸ“Š æˆåŠŸåŠ è½½ {total_records} æ¡å¯¹è¯å†å²è®°å½•ã€‚")
    print("ğŸ’¡ æ³¨æ„: ç®—æ³•å·²è‡ªåŠ¨è¿‡æ»¤åå·®æå¤§çš„ç‰¹æ®Šæ•°æ® (å¦‚æŸæ¬¡å¡é¡¿è¶…è¿‡4ç§’çš„ ASR)ï¼Œä»¥åæ˜ çœŸå®ä½“éªŒã€‚")

    # åˆ†åˆ«åˆ†ææœ€è¿‘ 10æ¬¡, 20æ¬¡, 50æ¬¡
    target_counts = [10, 20, 50]

    for count in target_counts:
        # å¦‚æœå†å²æ•°æ®æ²¡é‚£ä¹ˆå¤šï¼Œæœ€å¤šæ‰“å°åˆ°å®é™…æ•°é‡å°±ä¸å†æ‰“å°äº†
        if count > total_records and count != target_counts[0]:
            continue
        analyze_subset(records, min(count, total_records))


if __name__ == "__main__":
    main()